
R version 4.5.0 (2025-04-11) -- "How About a Twenty-Six"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "betareg"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('betareg')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("Beta01")
> ### * Beta01
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Beta01
> ### Title: Create a Zero- and/or One-Inflated Beta Distribution
> ### Aliases: Beta01 mean.Beta01 variance.Beta01 skewness.Beta01
> ###   kurtosis.Beta01 pdf.Beta01 log_pdf.Beta01 cdf.Beta01 quantile.Beta01
> ###   random.Beta01 support.Beta01 is_discrete.Beta01 is_continuous.Beta01
> 
> ### ** Examples
> 
> ## Don't show: 
>  if(!requireNamespace("distributions3")) {
+   if(interactive() || is.na(Sys.getenv("_R_CHECK_PACKAGE_NAME_", NA))) {
+     stop("not all packages required for the example are installed")
+   } else q() }
Loading required namespace: distributions3
> ## End(Don't show)
> ## package and random seed
> library("distributions3")

Attaching package: ‘distributions3’

The following object is masked from ‘package:stats’:

    Gamma

The following object is masked from ‘package:grDevices’:

    pdf

> set.seed(6020)
> 
> ## three beta distributions
> X <- Beta01(
+   mu  = c(0.25, 0.50, 0.75),
+   phi = c(1, 1, 2),
+   p0 = c(0.1, 0, 0),
+   p1 = c(0, 0, 0.3)
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:distributions3’

> nameEx("Beta4")
> ### * Beta4
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Beta4
> ### Title: Create a 4-Parameter Beta Distribution
> ### Aliases: Beta4 mean.Beta4 variance.Beta4 skewness.Beta4 kurtosis.Beta4
> ###   pdf.Beta4 log_pdf.Beta4 cdf.Beta4 quantile.Beta4 random.Beta4
> ###   support.Beta4 is_discrete.Beta4 is_continuous.Beta4
> 
> ### ** Examples
> 
> ## Don't show: 
>  if(!requireNamespace("distributions3")) {
+   if(interactive() || is.na(Sys.getenv("_R_CHECK_PACKAGE_NAME_", NA))) {
+     stop("not all packages required for the example are installed")
+   } else q() }
> ## End(Don't show)
> ## package and random seed
> library("distributions3")

Attaching package: ‘distributions3’

The following object is masked from ‘package:stats’:

    Gamma

The following object is masked from ‘package:grDevices’:

    pdf

> set.seed(6020)
> 
> ## three beta distributions
> X <- Beta4(
+   mu  = c(0.25, 0.50, 0.75),
+   phi = c(1, 1, 2),
+   theta1 = c(0, -0.1, -0.1),
+   theta2 = c(1, 1.1, 1.5)
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:distributions3’

> nameEx("BetaR")
> ### * BetaR
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: BetaR
> ### Title: Create a Beta Regression Distribution
> ### Aliases: BetaR mean.BetaR variance.BetaR skewness.BetaR kurtosis.BetaR
> ###   pdf.BetaR log_pdf.BetaR cdf.BetaR quantile.BetaR random.BetaR
> ###   support.BetaR is_discrete.BetaR is_continuous.BetaR
> 
> ### ** Examples
> 
> ## Don't show: 
>  if(!requireNamespace("distributions3")) {
+   if(interactive() || is.na(Sys.getenv("_R_CHECK_PACKAGE_NAME_", NA))) {
+     stop("not all packages required for the example are installed")
+   } else q() }
> ## End(Don't show)
> ## package and random seed
> library("distributions3")

Attaching package: ‘distributions3’

The following object is masked from ‘package:stats’:

    Gamma

The following object is masked from ‘package:grDevices’:

    pdf

> set.seed(6020)
> 
> ## three beta distributions
> X <- BetaR(
+   mu  = c(0.25, 0.50, 0.75),
+   phi = c(1, 1, 2)
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:distributions3’

> nameEx("CarTask")
> ### * CarTask
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: CarTask
> ### Title: Partition-Primed Probability Judgement Task for Car Dealership
> ### Aliases: CarTask
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("CarTask", package = "betareg")
> library("flexmix")
Loading required package: lattice
> car_betamix <- betamix(probability ~ 1, data = CarTask, k = 3,
+   extra_components = list(extraComponent(type = "uniform", coef = 1/2,
+   delta = 0.01), extraComponent(type = "uniform", coef = 1/4, delta = 0.01)),
+   FLXconcomitant = FLXPmultinom(~ task))
> 
> 
> 
> cleanEx()

detaching ‘package:flexmix’, ‘package:lattice’

> nameEx("FoodExpenditure")
> ### * FoodExpenditure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: FoodExpenditure
> ### Title: Proportion of Household Income Spent on Food
> ### Aliases: FoodExpenditure
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("FoodExpenditure", package = "betareg")
> 
> ## Ferrari and Cribari-Neto (2004)
> ## Section 4
> fe_lin <- lm(I(food/income) ~ income + persons, data = FoodExpenditure)
> library("lmtest")
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

> bptest(fe_lin)

	studentized Breusch-Pagan test

data:  fe_lin
BP = 5.9348, df = 2, p-value = 0.05144

> 
> ## Table 2
> fe_beta <- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)
> summary(fe_beta)

Call:
betareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)

Quantile residuals:
    Min      1Q  Median      3Q     Max 
-2.5328 -0.4599  0.1698  0.6416  1.7733 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -0.622548   0.223854  -2.781 0.005418 ** 
income      -0.012299   0.003036  -4.052 5.09e-05 ***
persons      0.118462   0.035341   3.352 0.000802 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    35.61       8.08   4.407 1.05e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 45.33 on 4 Df
Pseudo R-squared: 0.3878
Number of iterations: 28 (BFGS) + 4 (Fisher scoring) 
> 
> 
> 
> cleanEx()

detaching ‘package:lmtest’, ‘package:zoo’

> nameEx("GasolineYield")
> ### * GasolineYield
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: GasolineYield
> ### Title: Estimation of Gasoline Yields from Crude Oil
> ### Aliases: GasolineYield
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## IGNORE_RDIFF_BEGIN
> data("GasolineYield", package = "betareg")
> 
> gy1 <- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)
> summary(gy1)

Call:
betareg(formula = yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)

Quantile residuals:
    Min      1Q  Median      3Q     Max 
-1.9010 -0.6829 -0.0385  0.5531  2.1314 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -2.6949422  0.7625693  -3.534 0.000409 ***
gravity      0.0045412  0.0071419   0.636 0.524871    
pressure     0.0304135  0.0281007   1.082 0.279117    
temp10      -0.0110449  0.0022640  -4.879 1.07e-06 ***
temp         0.0105650  0.0005154  20.499  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)   248.24      62.02   4.003 6.26e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 75.68 on 6 Df
Pseudo R-squared: 0.9398
Number of iterations: 147 (BFGS) + 4 (Fisher scoring) 
> 
> ## Ferrari and Cribari-Neto (2004)
> gy2 <- betareg(yield ~ batch + temp, data = GasolineYield)
> ## Table 1
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Quantile residuals:
    Min      1Q  Median      3Q     Max 
-2.1396 -0.5698  0.1202  0.7040  1.7506 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.1595710  0.1823247 -33.784  < 2e-16 ***
batch1       1.7277289  0.1012294  17.067  < 2e-16 ***
batch2       1.3225969  0.1179020  11.218  < 2e-16 ***
batch3       1.5723099  0.1161045  13.542  < 2e-16 ***
batch4       1.0597141  0.1023598  10.353  < 2e-16 ***
batch5       1.1337518  0.1035232  10.952  < 2e-16 ***
batch6       1.0401618  0.1060365   9.809  < 2e-16 ***
batch7       0.5436922  0.1091275   4.982 6.29e-07 ***
batch8       0.4959007  0.1089257   4.553 5.30e-06 ***
batch9       0.3857930  0.1185933   3.253  0.00114 ** 
temp         0.0109669  0.0004126  26.577  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    440.3      110.0   4.002 6.29e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  84.8 on 12 Df
Pseudo R-squared: 0.9617
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> ## Figure 2
> par(mfrow = c(3, 2))
> plot(gy2, which = 1, type = "pearson", sub.caption = "")
> plot(gy2, which = 1, type = "deviance", sub.caption = "")
> plot(gy2, which = 5, type = "deviance", sub.caption = "")
> plot(gy2, which = 4, type = "pearson", sub.caption = "")
> plot(gy2, which = 2:3)
> par(mfrow = c(1, 1))
> 
> ## exclude 4th observation
> gy2a <- update(gy2, subset = -4)
> gy2a

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)

Coefficients (mean model with logit link):
(Intercept)       batch1       batch2       batch3       batch4       batch5  
   -6.35647      1.88688      1.37039      1.62512      1.08066      1.15158  
     batch6       batch7       batch8       batch9         temp  
    1.05766      0.56522      0.50066      0.38523      0.01146  

Phi coefficients (precision model with identity link):
(phi)  
577.8  

> summary(gy2a)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)

Quantile residuals:
    Min      1Q  Median      3Q     Max 
-2.0153 -0.8176  0.0897  0.6948  2.0746 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.3564713  0.1716020 -37.042  < 2e-16 ***
batch1       1.8868782  0.1001837  18.834  < 2e-16 ***
batch2       1.3703911  0.1042352  13.147  < 2e-16 ***
batch3       1.6251199  0.1028326  15.804  < 2e-16 ***
batch4       1.0806596  0.0897855  12.036  < 2e-16 ***
batch5       1.1515826  0.0906857  12.699  < 2e-16 ***
batch6       1.0576556  0.0929172  11.383  < 2e-16 ***
batch7       0.5652219  0.0956100   5.912 3.39e-09 ***
batch8       0.5006625  0.0953210   5.252 1.50e-07 ***
batch9       0.3852258  0.1037500   3.713 0.000205 ***
temp         0.0114588  0.0003945  29.050  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    577.8      146.7   3.938 8.22e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 86.62 on 12 Df
Pseudo R-squared: 0.9662
Number of iterations: 51 (BFGS) + 4 (Fisher scoring) 
> ## IGNORE_RDIFF_END
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("ImpreciseTask")
> ### * ImpreciseTask
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ImpreciseTask
> ### Title: Imprecise Probabilities for Sunday Weather and Boeing Stock Task
> ### Aliases: ImpreciseTask
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("ImpreciseTask", package = "betareg")
> library("flexmix")
Loading required package: lattice
> wt_betamix <- betamix(location ~ difference * task, data = ImpreciseTask, k = 2,
+   extra_components = extraComponent(type = "betareg", coef =
+     list(mean = 0, precision = 8)),
+   FLXconcomitant = FLXPmultinom(~ task))
> 
> 
> 
> cleanEx()

detaching ‘package:flexmix’, ‘package:lattice’

> nameEx("LossAversion")
> ### * LossAversion
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: LossAversion
> ### Title: (No) Myopic Loss Aversion in Adolescents
> ### Aliases: LossAversion
> ### Keywords: datasets
> 
> ### ** Examples
> 
> options(digits = 4)
> 
> ## data and add ad-hoc scaling (a la Smithson & Verkuilen)
> data("LossAversion", package = "betareg")
> LossAversion <- transform(LossAversion,
+   invests = (invest * (nrow(LossAversion) - 1) + 0.5)/nrow(LossAversion))
> 
> 
> ## models: normal (with constant variance), beta, extended-support beta mixture
> la_n <- lm(invest ~ grade * (arrangement + age) + male, data = LossAversion)
> summary(la_n)

Call:
lm(formula = invest ~ grade * (arrangement + age) + male, data = LossAversion)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.7735 -0.1967  0.0024  0.1916  0.5724 

Coefficients:
                           Estimate Std. Error t value Pr(>|t|)    
(Intercept)                  0.2844     0.1575    1.81  0.07136 .  
grade10-12                  -0.8437     0.2815   -3.00  0.00284 ** 
arrangementteam              0.0628     0.0302    2.08  0.03788 *  
age                          0.0115     0.0124    0.93  0.35041    
maleyes                      0.1035     0.0232    4.46  9.9e-06 ***
grade10-12:arrangementteam   0.1507     0.0455    3.32  0.00097 ***
grade10-12:age               0.0458     0.0185    2.47  0.01380 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.247 on 563 degrees of freedom
Multiple R-squared:  0.158,	Adjusted R-squared:  0.149 
F-statistic: 17.7 on 6 and 563 DF,  p-value: <2e-16

> 
> 
> 
> 
> cleanEx()
> nameEx("MockJurors")
> ### * MockJurors
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MockJurors
> ### Title: Confidence of Mock Jurors in Their Verdicts
> ### Aliases: MockJurors
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("MockJurors", package = "betareg")
> library("lmtest")
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

> 
> ## Smithson & Verkuilen (2006, Table 1)
> ## variable dispersion model
> ## (NOTE: numerical rather than analytical Hessian is used for replication,
> ##  Smithson & Verkuilen erroneously compute one-sided p-values)
> mj_vd <- betareg(confidence ~ verdict * conflict | verdict * conflict,
+   data = MockJurors, hessian = TRUE)
> summary(mj_vd)

Call:
betareg(formula = confidence ~ verdict * conflict | verdict * conflict, 
    data = MockJurors, hessian = TRUE)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.476 -0.665 -0.099  0.600  2.644 

Coefficients (mean model with logit link):
                 Estimate Std. Error z value Pr(>|z|)    
(Intercept)       0.91240    0.10398    8.77   <2e-16 ***
verdict           0.00504    0.10398    0.05   0.9614    
conflict          0.16857    0.10398    1.62   0.1050    
verdict:conflict  0.28001    0.10398    2.69   0.0071 ** 

Phi coefficients (precision model with log link):
                 Estimate Std. Error z value Pr(>|z|)    
(Intercept)         1.173      0.128    9.18   <2e-16 ***
verdict            -0.330      0.128   -2.58   0.0099 ** 
conflict            0.220      0.128    1.72   0.0858 .  
verdict:conflict    0.316      0.128    2.47   0.0133 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 40.1 on 8 Df
Pseudo R-squared: 0.0389
Number of iterations in BFGS optimization: 19 
> 
> ## model selection for beta regression: null model, fixed dispersion model (p. 61)
> mj_null <- betareg(confidence ~ 1 | 1, data = MockJurors)
> mj_fd <-   betareg(confidence ~ verdict * conflict | 1, data = MockJurors)
> lrtest(mj_null, mj_fd)
Likelihood ratio test

Model 1: confidence ~ 1 | 1
Model 2: confidence ~ verdict * conflict | 1
  #Df LogLik Df Chisq Pr(>Chisq)
1   2   28.2                    
2   5   30.6  3  4.71       0.19
> lrtest(mj_null, mj_vd)
Likelihood ratio test

Model 1: confidence ~ 1 | 1
Model 2: confidence ~ verdict * conflict | verdict * conflict
  #Df LogLik Df Chisq Pr(>Chisq)    
1   2   28.2                        
2   8   40.1  6  23.8    0.00057 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> ## McFadden's pseudo-R-squared
> 1 - as.vector(logLik(mj_null)/logLik(mj_vd))
[1] 0.2964
> 
> ## visualization
> if(require("lattice")) {
+   histogram(~ confidence | conflict + verdict, data = MockJurors,
+     col = "lightgray", breaks = 0:10/10, type = "density")
+ }
Loading required package: lattice
> 
> ## see demo("SmithsonVerkuilen2006", package = "betareg") for more details
> 
> 
> 
> cleanEx()

detaching ‘package:lattice’, ‘package:lmtest’, ‘package:zoo’

> nameEx("ReadingSkills")
> ### * ReadingSkills
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ReadingSkills
> ### Title: Dyslexia and IQ Predicting Reading Accuracy
> ### Aliases: ReadingSkills
> ### Keywords: datasets
> 
> ### ** Examples
> 
> options(digits = 4)
> data("ReadingSkills", package = "betareg")
> 
> ## Smithson & Verkuilen (2006, Table 5)
> ## OLS regression
> ## (Note: typo in iq coefficient: 0.3954 instead of 0.3594)
> rs_ols <- lm(qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)
> summary(rs_ols)

Call:
lm(formula = qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.6640 -0.3797  0.0369  0.4089  2.5035 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)    1.601      0.226    7.09  1.4e-08 ***
dyslexia      -1.206      0.226   -5.34  4.0e-06 ***
iq             0.359      0.225    1.59    0.119    
dyslexia:iq   -0.423      0.225   -1.88    0.068 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.2 on 40 degrees of freedom
Multiple R-squared:  0.615,	Adjusted R-squared:  0.586 
F-statistic: 21.3 on 3 and 40 DF,  p-value: 2.08e-08

> ## Beta regression (with numerical rather than analytic standard errors)
> ## (Note: Smithson & Verkuilen erroneously compute one-sided p-values)
> rs_beta <- betareg(accuracy ~ dyslexia * iq | dyslexia + iq,
+   data = ReadingSkills, hessian = TRUE)
> summary(rs_beta)

Call:
betareg(formula = accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills, 
    hessian = TRUE)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.362 -0.587  0.303  0.942  1.587 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.123      0.151    7.44  9.8e-14 ***
dyslexia      -0.742      0.151   -4.90  9.7e-07 ***
iq             0.486      0.167    2.91  0.00360 ** 
dyslexia:iq   -0.581      0.173   -3.37  0.00076 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    3.304      0.227   14.59  < 2e-16 ***
dyslexia       1.747      0.294    5.94  2.8e-09 ***
iq             1.229      0.460    2.67   0.0075 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 65.9 on 7 Df
Pseudo R-squared: 0.576
Number of iterations in BFGS optimization: 25 
> 
> ## Extended-support beta mixture regression (Kosmidis & Zeileis 2024)
> rs_xbx <- betareg(accuracy1 ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)
Loading required namespace: numDeriv
> summary(rs_xbx)

Call:
betareg(formula = accuracy1 ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)

Randomized quantile residuals:
   Min     1Q Median     3Q    Max 
-2.418 -0.598  0.010  0.805  1.721 

Coefficients (mu model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    0.903      0.217    4.17  3.1e-05 ***
dyslexia      -0.606      0.182   -3.34  0.00084 ***
iq             0.329      0.188    1.75  0.07989 .  
dyslexia:iq   -0.388      0.199   -1.94  0.05205 .  

Phi coefficients (phi model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    3.499      0.530    6.60  4.1e-11 ***
dyslexia       1.736      0.449    3.86  0.00011 ***
iq             0.697      0.571    1.22  0.22243    

Exceedence parameter (extended-support xbetax model):
        Estimate Std. Error z value Pr(>|z|)  
Log(nu)   -1.790      0.854    -2.1    0.036 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Exceedence parameter nu: 0.167
Type of estimator: ML (maximum likelihood)
Log-likelihood: 18.5 on 8 Df
Number of iterations in BFGS optimization: 29 
> 
> ## Coefficients in XBX are typically somewhat shrunken compared to beta
> cbind(XBX = coef(rs_xbx), Beta = c(coef(rs_beta), NA))
                      XBX    Beta
(Intercept)        0.9030  1.1232
dyslexia          -0.6065 -0.7416
iq                 0.3288  0.4864
dyslexia:iq       -0.3875 -0.5813
(phi)_(Intercept)  3.4990  3.3044
(phi)_dyslexia     1.7360  1.7466
(phi)_iq           0.6965  1.2291
Log(nu)           -1.7905      NA
> 
> ## Visualization
> plot(accuracy1 ~ iq, data = ReadingSkills, col = c(4, 2)[dyslexia], pch = 19)
> nd <- data.frame(dyslexia = "no", iq = -30:30/10)
> lines(nd$iq, predict(rs_xbx, nd), col = 4)
> lines(nd$iq, predict(rs_beta, nd), col = 4, lty = 5)
> lines(nd$iq, plogis(predict(rs_ols, nd)), col = 4, lty = 3)
> nd <- data.frame(dyslexia = "yes", iq = -30:30/10)
> lines(nd$iq, predict(rs_xbx, nd), col = 2)
> lines(nd$iq, predict(rs_beta, nd), col = 2, lty = 5)
> lines(nd$iq, plogis(predict(rs_ols, nd)), col = 2, lty = 3)
> legend("topleft", c("Dyslexia: no", "Dyslexia: yes", "OLS", "XBX", "Beta"),
+   lty = c(0, 0, 3, 1, 5), pch = c(19, 19, NA, NA, NA), col = c(4, 2, 1, 1, 1), bty = "n")
> 
> ## see demo("SmithsonVerkuilen2006", package = "betareg") for further details
> 
> 
> 
> cleanEx()
> nameEx("StressAnxiety")
> ### * StressAnxiety
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: StressAnxiety
> ### Title: Dependency of Anxiety on Stress
> ### Aliases: StressAnxiety
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("StressAnxiety", package = "betareg")
> StressAnxiety <- StressAnxiety[order(StressAnxiety$stress),]
> 
> ## Smithson & Verkuilen (2006, Table 4)
> sa_null <- betareg(anxiety ~ 1 | 1,
+   data = StressAnxiety, hessian = TRUE)
> sa_stress <- betareg(anxiety ~ stress | stress,
+   data = StressAnxiety, hessian = TRUE)
> summary(sa_null)

Call:
betareg(formula = anxiety ~ 1 | 1, data = StressAnxiety, hessian = TRUE)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-0.838 -0.838 -0.447  0.622  3.240 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -2.2440     0.0988   -22.7   <2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.796      0.123    14.6   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  239 on 2 Df
Number of iterations in BFGS optimization: 9 
> summary(sa_stress)

Call:
betareg(formula = anxiety ~ stress | stress, data = StressAnxiety, hessian = TRUE)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.012 -0.795 -0.183  0.566  3.114 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   -4.024      0.144   -27.9   <2e-16 ***
stress         4.941      0.441    11.2   <2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    3.961      0.251   15.78  < 2e-16 ***
stress        -4.273      0.753   -5.67  1.4e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  302 on 4 Df
Pseudo R-squared: 0.475
Number of iterations in BFGS optimization: 16 
> AIC(sa_null, sa_stress)
          df    AIC
sa_null    2 -474.9
sa_stress  4 -595.9
> 1 - as.vector(logLik(sa_null)/logLik(sa_stress))
[1] 0.207
> 
> ## visualization
> attach(StressAnxiety)
> plot(jitter(anxiety) ~ jitter(stress),
+   xlab = "Stress", ylab = "Anxiety",
+   xlim = c(0, 1), ylim = c(0, 1))
> lines(lowess(anxiety ~ stress))
> lines(fitted(sa_stress) ~ stress, lty = 2)
> lines(fitted(lm(anxiety ~ stress)) ~ stress, lty = 3)
> legend("topleft", c("lowess", "betareg", "lm"), lty = 1:3, bty = "n")
> detach(StressAnxiety)
> 
> ## see demo("SmithsonVerkuilen2006", package = "betareg") for more details
> 
> 
> 
> cleanEx()
> nameEx("WeatherTask")
> ### * WeatherTask
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: WeatherTask
> ### Title: Weather Task with Priming and Precise and Imprecise
> ###   Probabilities
> ### Aliases: WeatherTask
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("WeatherTask", package = "betareg")
> library("flexmix")
Loading required package: lattice
> wt_betamix <- betamix(agreement ~ 1, data = WeatherTask, k = 2,
+   extra_components = extraComponent(type = "betareg", coef =
+     list(mean = 0, precision = 2)),
+   FLXconcomitant = FLXPmultinom(~ priming + eliciting))
> 
> 
> 
> cleanEx()

detaching ‘package:flexmix’, ‘package:lattice’

> nameEx("XBeta")
> ### * XBeta
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: XBeta
> ### Title: Create an Extended-Support Beta Distribution
> ### Aliases: XBeta mean.XBeta variance.XBeta skewness.XBeta kurtosis.XBeta
> ###   pdf.XBeta log_pdf.XBeta cdf.XBeta quantile.XBeta random.XBeta
> ###   support.XBeta is_discrete.XBeta is_continuous.XBeta
> 
> ### ** Examples
> 
> ## Don't show: 
>  if(!requireNamespace("distributions3")) {
+   if(interactive() || is.na(Sys.getenv("_R_CHECK_PACKAGE_NAME_", NA))) {
+     stop("not all packages required for the example are installed")
+   } else q() }
> ## End(Don't show)
> ## package and random seed
> library("distributions3")

Attaching package: ‘distributions3’

The following object is masked from ‘package:stats’:

    Gamma

The following object is masked from ‘package:grDevices’:

    pdf

> set.seed(6020)
> 
> ## three beta distributions
> X <- XBeta(
+   mu  = c(0.25, 0.50, 0.75),
+   phi = c(1, 1, 2),
+   nu = c(0, 0.1, 0.2)
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:distributions3’

> nameEx("XBetaX")
> ### * XBetaX
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: XBetaX
> ### Title: Create an Extended-Support Beta Mixture Distribution
> ### Aliases: XBetaX mean.XBetaX variance.XBetaX skewness.XBetaX
> ###   kurtosis.XBetaX pdf.XBetaX log_pdf.XBetaX cdf.XBetaX quantile.XBetaX
> ###   random.XBetaX support.XBetaX is_discrete.XBetaX is_continuous.XBetaX
> 
> ### ** Examples
> 
> ## Don't show: 
>  if(!requireNamespace("distributions3")) {
+   if(interactive() || is.na(Sys.getenv("_R_CHECK_PACKAGE_NAME_", NA))) {
+     stop("not all packages required for the example are installed")
+   } else q() }
> ## End(Don't show)
> ## package and random seed
> library("distributions3")

Attaching package: ‘distributions3’

The following object is masked from ‘package:stats’:

    Gamma

The following object is masked from ‘package:grDevices’:

    pdf

> set.seed(6020)
> 
> ## three beta distributions
> X <- XBetaX(
+   mu  = c(0.25, 0.50, 0.75),
+   phi = c(1, 1, 2),
+   nu = c(0, 0.1, 0.2)
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:distributions3’

> nameEx("betamix")
> ### * betamix
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betamix
> ### Title: Finite Mixtures of Beta Regression for Rates and Proportions
> ### Aliases: betamix extraComponent fitted,FLXMRbeta-method
> ###   fitted,betamix-method posterior,betamix,ANY-method
> ###   clusters,betamix,ANY-method predict,FLXMRbeta-method
> ###   predict,FLXMRbetafix-method predict,betamix-method
> ### Keywords: regression cluster
> 
> ### ** Examples
> 
> options(digits = 4)
> 
> ## data with two groups of dyslexic and non-dyslexic children
> data("ReadingSkills", package = "betareg")
> 
> suppressWarnings(RNGversion("3.5.0"))
> set.seed(4040)
> ## try to capture accuracy ~ iq relationship (without using dyslexia
> ## information) using two beta regression components and one additional
> ## extra component for a perfect reading score
> rs_mix <- betamix(accuracy ~ iq, data = ReadingSkills, k = 3,
+   nstart = 10, extra_components = extraComponent(type = "uniform",
+   coef = 0.99, delta = 0.01))
> 
> ## visualize result
> ## intensities based on posterior probabilities
> prob <- 2 * (posterior(rs_mix)[cbind(1:nrow(ReadingSkills),
+    clusters(rs_mix))] - 0.5)
> ## associated HCL colors
> col0 <- hcl(c(260, 0, 130), 65, 45, fixup = FALSE)
> col1 <- col0[clusters(rs_mix)]
> col2 <- hcl(c(260, 0, 130)[clusters(rs_mix)], 65 * abs(prob)^1.5,
+    95 - 50 * abs(prob)^1.5, fixup = FALSE)
> ## scatter plot
> plot(accuracy ~ iq, data = ReadingSkills, col = col2, pch = 19,
+    cex = 1.5, xlim = c(-2, 2))
> points(accuracy ~ iq, data = ReadingSkills, cex = 1.5, pch = 1,
+    col = col1)
> ## fitted lines
> iq <- -30:30/10
> cf <- rbind(coef(rs_mix, model = "mean", component = 1:2),
+    c(qlogis(0.99), 0))
> for(i in 1:3)
+    lines(iq, plogis(cf[i, 1] + cf[i, 2] * iq), lwd = 2,
+          col = col0[i])
> 
> ## refit the model including a concomitant variable model using the
> ## dyslexia information with some noise to avoid complete separation
> ## between concomitant variable and component memberships
> set.seed(4040)
> w <- rnorm(nrow(ReadingSkills), 
+            c(-1, 1)[as.integer(ReadingSkills$dyslexia)])
> 
> ## The argument FLXconcomitant can be omitted when specifying
> ## the model via a three part formula given by
> ## accuracy ~ iq | 1 | w
> ## The posteriors from the previously fitted model are used
> ## for initialization.
> library("flexmix")
Loading required package: lattice
> rs_mix2 <- betamix(accuracy ~ iq, data = ReadingSkills,
+   extra_components = extraComponent(type = "uniform",
+   coef = 0.99, delta = 0.01), cluster = posterior(rs_mix),
+   FLXconcomitant = FLXPmultinom(~w))
> coef(rs_mix2, which = "concomitant")
  (Intercept)       w
1      0.0000  0.0000
2      0.8114  1.0778
3     -0.1195 -0.3488
> summary(rs_mix2, which = "concomitant")
$Comp.2
            Estimate Std. Error z value Pr(>|z|)  
(Intercept)    0.821      0.882    0.93     0.35  
w              1.078      0.497    2.17     0.03 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

$Comp.3
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   -0.113      0.812   -0.14     0.89
w             -0.346      0.452   -0.77     0.44

> 
> 
> 
> cleanEx()

detaching ‘package:flexmix’, ‘package:lattice’

> nameEx("betar_family")
> ### * betar_family
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betar_family
> ### Title: Family Objects for (Extended-Support) Beta Regression
> ### Aliases: betar_family xbetax_family
> 
> ### ** Examples
> 
> ## IGNORE_RDIFF_BEGIN
> ## Don't show: 
>  if(!requireNamespace("bamlss")) {
+   if(interactive() || is.na(Sys.getenv("_R_CHECK_PACKAGE_NAME_", NA))) {
+     stop("not all packages required for the example are installed")
+   } else q() }
Loading required namespace: bamlss
> ## End(Don't show)
> ## package and data
> library("betareg")
> library("bamlss")
Loading required package: coda
Loading required package: colorspace
Loading required package: distributions3

Attaching package: ‘distributions3’

The following object is masked from ‘package:stats’:

    Gamma

The following object is masked from ‘package:grDevices’:

    pdf

Loading required package: mgcv
Loading required package: nlme
This is mgcv 1.9-3. For overview type 'help("mgcv-package")'.
-
For citation info, use citation("bamlss") and see http://www.bamlss.org/.

Attaching package: ‘bamlss’

The following object is masked from ‘package:mgcv’:

    smooth.construct

> data("ReadingSkills", package = "betareg")
> 
> ## classical beta regression via ML
> rs1 <- betareg(accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)
> 
> ## Bayesian additive model (with low number of iterations to speed up the example)
> set.seed(0)
> rs2 <- bamlss(accuracy ~ s(iq, by = dyslexia) | dyslexia + iq, data = ReadingSkills,
+   family = betar_family(), eps = 1e-7, n.iter = 400, burnin = 100)
AICc  -0.8829 logPost -64.6792 logLik  21.6241 edf 13.973 eps 1.0000 iteration   1
AICc -51.8915 logPost -25.8044 logLik  39.7035 edf 10.242 eps 2.8731 iteration   2
AICc -68.1251 logPost  -7.3858 logLik  46.8183 edf 9.6642 eps 0.5561 iteration   3
AICc -73.1290 logPost   4.7269 logLik  48.3399 edf 9.0783 eps 0.0895 iteration   4
AICc -74.7842 logPost   5.5545 logLik  49.1675 edf 9.0783 eps 0.0629 iteration   5
AICc -75.7464 logPost   6.0357 logLik  49.6487 edf 9.0783 eps 0.0559 iteration   6
AICc -76.3072 logPost   6.3160 logLik  49.9291 edf 9.0783 eps 0.2490 iteration   7
AICc -77.3399 logPost   6.8324 logLik  50.4454 edf 9.0783 eps 0.2694 iteration   8
AICc -77.6557 logPost   6.9903 logLik  50.6033 edf 9.0783 eps 0.0207 iteration   9
AICc -77.8176 logPost   7.0713 logLik  50.6843 edf 9.0783 eps 0.0123 iteration  10
AICc -80.2391 logPost   8.7295 logLik  50.7321 edf 8.3559 eps 0.0099 iteration  11
AICc -81.1323 logPost -61.6299 logLik  50.7922 edf 8.1090 eps 0.0333 iteration  12
AICc -81.3164 logPost -654.389 logLik  50.8351 edf 8.0774 eps 0.0089 iteration  13
AICc -81.3726 logPost -4694.96 logLik  50.8579 edf 8.0740 eps 0.0054 iteration  14
AICc -81.4322 logPost -25766.3 logLik  50.8816 edf 8.0700 eps 0.0077 iteration  15
AICc -81.6598 logPost -2043.53 logLik  50.9498 edf 8.0406 eps 0.0179 iteration  16
AICc -82.3830 logPost -8852.97 logLik  51.1594 edf 7.9421 eps 0.0137 iteration  17
AICc -82.7904 logPost -13085.5 logLik  51.2898 edf 7.8944 eps 0.0124 iteration  18
AICc -82.9776 logPost -13740.2 logLik  51.3740 edf 7.8883 eps 0.0431 iteration  19
AICc -83.0956 logPost -13809.0 logLik  51.4431 edf 7.8949 eps 0.0096 iteration  20
AICc -83.2026 logPost -13815.6 logLik  51.4812 edf 7.8848 eps 0.0058 iteration  21
AICc -83.2582 logPost -13816.0 logLik  51.5109 edf 7.8861 eps 0.0574 iteration  22
AICc -83.3488 logPost -13815.9 logLik  51.5729 edf 7.8970 eps 0.0084 iteration  23
AICc -83.4298 logPost -13815.7 logLik  51.5929 edf 7.8836 eps 0.0035 iteration  24
AICc -83.4578 logPost -13815.6 logLik  51.6069 edf 7.8837 eps 0.0029 iteration  25
AICc -83.4771 logPost -13815.4 logLik  51.6166 edf 7.8837 eps 0.0025 iteration  26
AICc -83.4921 logPost -13815.3 logLik  51.6242 edf 7.8837 eps 0.0042 iteration  27
AICc -83.5087 logPost -13815.3 logLik  51.6291 edf 7.8815 eps 0.0021 iteration  28
AICc -83.5136 logPost -13815.2 logLik  51.6323 edf 7.8820 eps 0.0016 iteration  29
AICc -83.5176 logPost -13815.1 logLik  51.6343 edf 7.8820 eps 0.0013 iteration  30
AICc -83.5199 logPost -13815.1 logLik  51.6355 edf 7.8820 eps 0.0011 iteration  31
AICc -83.5219 logPost -13815.1 logLik  51.6365 edf 7.8820 eps 0.0042 iteration  32
AICc -83.5216 logPost -13815.0 logLik  51.6382 edf 7.8832 eps 0.0022 iteration  33
AICc -83.5300 logPost -13815.0 logLik  51.6383 edf 7.8806 eps 0.0009 iteration  34
AICc -83.5294 logPost -13815.0 logLik  51.6384 edf 7.8808 eps 0.0003 iteration  35
AICc -83.5293 logPost -13815.0 logLik  51.6384 edf 7.8809 eps 0.0000 iteration  36
AICc -83.5293 logPost -13815.0 logLik  51.6384 edf 7.8809 eps 0.0000 iteration  37
AICc -83.5293 logPost -13815.0 logLik  51.6384 edf 7.8809 eps 0.0000 iteration  38
AICc -83.5293 logPost -13815.0 logLik  51.6384 edf 7.8809 eps 0.0000 iteration  39
AICc -83.5293 logPost -13815.0 logLik  51.6384 edf 7.8809 eps 0.0000 iteration  39
elapsed time:  1.40sec
Starting the sampler...

|                    |   0%  1.37sec
|*                   |   5%  1.31sec  0.07sec
|**                  |  10%  1.33sec  0.15sec
|***                 |  15%  1.24sec  0.22sec
|****                |  20%  1.15sec  0.29sec
|*****               |  25%  1.07sec  0.36sec
|******              |  30%  1.09sec  0.47sec
|*******             |  35%  1.01sec  0.54sec
|********            |  40%  0.93sec  0.62sec
|*********           |  45%  0.86sec  0.70sec
|**********          |  50%  0.78sec  0.78sec
|***********         |  55%  0.70sec  0.85sec
|************        |  60%  0.62sec  0.92sec
|*************       |  65%  0.54sec  1.01sec
|**************      |  70%  0.46sec  1.08sec
|***************     |  75%  0.39sec  1.16sec
|****************    |  80%  0.31sec  1.24sec
|*****************   |  85%  0.23sec  1.32sec
|******************  |  90%  0.15sec  1.39sec
|******************* |  95%  0.08sec  1.46sec
|********************| 100%  0.00sec  1.55sec
> 
> ## Bayesian model shrinks the effects compared to ML
> plot(accuracy ~ iq, data = ReadingSkills, pch = 19, col = dyslexia)
> nd <- data.frame(
+   iq = rep(-19:20/10, 2),
+   dyslexia = factor(rep(c("no", "yes"), each = 40), levels = c("no", "yes"))
+ )
> nd$betareg <- predict(rs1, newdata = nd, type = "response")
> nd$bamlss  <- predict(rs2, newdata = nd, type = "parameter", model = "mu")
> lines(betareg ~ iq, data = nd, subset = dyslexia == "no",  col = 1, lwd = 2, lty = 1)
> lines(betareg ~ iq, data = nd, subset = dyslexia == "yes", col = 2, lwd = 2, lty = 1)
> lines(bamlss  ~ iq, data = nd, subset = dyslexia == "no",  col = 1, lwd = 2, lty = 2)
> lines(bamlss  ~ iq, data = nd, subset = dyslexia == "yes", col = 2, lwd = 2, lty = 2)
> legend("topleft", c("Dyslexia: no", "Dyslexia: yes", "betareg", "bamlss"),
+   lty = c(0, 0, 1, 2), pch = c(19, 19, NA, NA), col = c(1, 2, 1, 1), bty = "n")
> ## IGNORE_RDIFF_END
> 
> ## xbetax_family(): requires more time due to Gaussian quadrature
> ## for gamlss2: install.packages("gamlss2", repos = "https://gamlss-dev.R-universe.dev")
> 
> 
> 
> cleanEx()

detaching ‘package:bamlss’, ‘package:mgcv’, ‘package:nlme’,
  ‘package:distributions3’, ‘package:colorspace’, ‘package:coda’

> nameEx("betareg")
> ### * betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betareg
> ### Title: Beta Regression for Rates and Proportions
> ### Aliases: betareg betareg.fit
> ### Keywords: regression
> 
> ### ** Examples
> 
> options(digits = 4)
> 
> ## Section 4 from Ferrari and Cribari-Neto (2004)
> data("GasolineYield", package = "betareg")
> data("FoodExpenditure", package = "betareg")
> 
> ## Table 1
> gy <- betareg(yield ~ batch + temp, data = GasolineYield)
> summary(gy)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.140 -0.570  0.120  0.704  1.751 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.159571   0.182325  -33.78  < 2e-16 ***
batch1       1.727729   0.101229   17.07  < 2e-16 ***
batch2       1.322597   0.117902   11.22  < 2e-16 ***
batch3       1.572310   0.116105   13.54  < 2e-16 ***
batch4       1.059714   0.102360   10.35  < 2e-16 ***
batch5       1.133752   0.103523   10.95  < 2e-16 ***
batch6       1.040162   0.106036    9.81  < 2e-16 ***
batch7       0.543692   0.109127    4.98  6.3e-07 ***
batch8       0.495901   0.108926    4.55  5.3e-06 ***
batch9       0.385793   0.118593    3.25   0.0011 ** 
temp         0.010967   0.000413   26.58  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)      440        110       4  6.3e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 84.8 on 12 Df
Pseudo R-squared: 0.962
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> 
> ## Table 2
> fe_lin <- lm(I(food/income) ~ income + persons, data = FoodExpenditure)
> library("lmtest")
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

> bptest(fe_lin)

	studentized Breusch-Pagan test

data:  fe_lin
BP = 5.9, df = 2, p-value = 0.05

> fe_beta <- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)
> summary(fe_beta)

Call:
betareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.533 -0.460  0.170  0.642  1.773 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -0.62255    0.22385   -2.78   0.0054 ** 
income      -0.01230    0.00304   -4.05  5.1e-05 ***
persons      0.11846    0.03534    3.35   0.0008 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    35.61       8.08    4.41    1e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 45.3 on 4 Df
Pseudo R-squared: 0.388
Number of iterations: 28 (BFGS) + 4 (Fisher scoring) 
> 
> ## nested model comparisons via Wald and LR tests
> fe_beta2 <- betareg(I(food/income) ~ income, data = FoodExpenditure)
> lrtest(fe_beta, fe_beta2)
Likelihood ratio test

Model 1: I(food/income) ~ income + persons
Model 2: I(food/income) ~ income
  #Df LogLik Df Chisq Pr(>Chisq)   
1   4   45.3                       
2   3   40.5 -1  9.65     0.0019 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> waldtest(fe_beta, fe_beta2)
Wald test

Model 1: I(food/income) ~ income + persons
Model 2: I(food/income) ~ income
  Res.Df Df Chisq Pr(>Chisq)    
1     34                        
2     35 -1  11.2      8e-04 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> 
> ## Section 3 from online supplements to Simas et al. (2010)
> ## mean model as in gy above
> ## precision model with regressor temp
> gy2 <- betareg(yield ~ batch + temp | temp, data = GasolineYield)
> 
> ## MLE column in Table 19
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp | temp, data = GasolineYield)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.104 -0.585 -0.143  0.690  2.520 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -5.923236   0.183526  -32.27  < 2e-16 ***
batch1       1.601988   0.063856   25.09  < 2e-16 ***
batch2       1.297266   0.099100   13.09  < 2e-16 ***
batch3       1.565338   0.099739   15.69  < 2e-16 ***
batch4       1.030072   0.063288   16.28  < 2e-16 ***
batch5       1.154163   0.065643   17.58  < 2e-16 ***
batch6       1.019445   0.066351   15.36  < 2e-16 ***
batch7       0.622259   0.065632    9.48  < 2e-16 ***
batch8       0.564583   0.060185    9.38  < 2e-16 ***
batch9       0.359439   0.067141    5.35  8.6e-08 ***
temp         0.010359   0.000436   23.75  < 2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  1.36409    1.22578    1.11     0.27    
temp         0.01457    0.00362    4.03  5.7e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:   87 on 13 Df
Pseudo R-squared: 0.952
Number of iterations: 33 (BFGS) + 28 (Fisher scoring) 
> 
> ## LRT row in Table 18
> lrtest(gy, gy2)
Likelihood ratio test

Model 1: yield ~ batch + temp
Model 2: yield ~ batch + temp | temp
  #Df LogLik Df Chisq Pr(>Chisq)  
1  12   84.8                      
2  13   87.0  1  4.36      0.037 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> 
> 
> cleanEx()

detaching ‘package:lmtest’, ‘package:zoo’

> nameEx("betareg.control")
> ### * betareg.control
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betareg.control
> ### Title: Control Parameters for Beta Regression
> ### Aliases: betareg.control
> ### Keywords: regression
> 
> ### ** Examples
> 
> options(digits = 4)
> 
> data("GasolineYield", package = "betareg")
> 
> ## regression with phi as full model parameter
> gy1 <- betareg(yield ~ batch + temp, data = GasolineYield)
> gy1

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Coefficients (mean model with logit link):
(Intercept)       batch1       batch2       batch3       batch4       batch5  
     -6.160        1.728        1.323        1.572        1.060        1.134  
     batch6       batch7       batch8       batch9         temp  
      1.040        0.544        0.496        0.386        0.011  

Phi coefficients (precision model with identity link):
(phi)  
  440  

> 
> ## regression with phi as nuisance parameter
> gy2 <- betareg(yield ~ batch + temp, data = GasolineYield, phi = FALSE)
> gy2

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)

Coefficients (mean model with logit link):
(Intercept)       batch1       batch2       batch3       batch4       batch5  
     -6.160        1.728        1.323        1.572        1.060        1.134  
     batch6       batch7       batch8       batch9         temp  
      1.040        0.544        0.496        0.386        0.011  

> 
> ## compare reported output
> coef(gy1)
(Intercept)      batch1      batch2      batch3      batch4      batch5 
   -6.15957     1.72773     1.32260     1.57231     1.05971     1.13375 
     batch6      batch7      batch8      batch9        temp       (phi) 
    1.04016     0.54369     0.49590     0.38579     0.01097   440.27839 
> coef(gy2)
(Intercept)      batch1      batch2      batch3      batch4      batch5 
   -6.15957     1.72773     1.32260     1.57231     1.05971     1.13375 
     batch6      batch7      batch8      batch9        temp 
    1.04016     0.54369     0.49590     0.38579     0.01097 
> summary(gy1)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.140 -0.570  0.120  0.704  1.751 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.159571   0.182325  -33.78  < 2e-16 ***
batch1       1.727729   0.101229   17.07  < 2e-16 ***
batch2       1.322597   0.117902   11.22  < 2e-16 ***
batch3       1.572310   0.116105   13.54  < 2e-16 ***
batch4       1.059714   0.102360   10.35  < 2e-16 ***
batch5       1.133752   0.103523   10.95  < 2e-16 ***
batch6       1.040162   0.106036    9.81  < 2e-16 ***
batch7       0.543692   0.109127    4.98  6.3e-07 ***
batch8       0.495901   0.108926    4.55  5.3e-06 ***
batch9       0.385793   0.118593    3.25   0.0011 ** 
temp         0.010967   0.000413   26.58  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)      440        110       4  6.3e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 84.8 on 12 Df
Pseudo R-squared: 0.962
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.140 -0.570  0.120  0.704  1.751 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.159571   0.182325  -33.78  < 2e-16 ***
batch1       1.727729   0.101229   17.07  < 2e-16 ***
batch2       1.322597   0.117902   11.22  < 2e-16 ***
batch3       1.572310   0.116105   13.54  < 2e-16 ***
batch4       1.059714   0.102360   10.35  < 2e-16 ***
batch5       1.133752   0.103523   10.95  < 2e-16 ***
batch6       1.040162   0.106036    9.81  < 2e-16 ***
batch7       0.543692   0.109127    4.98  6.3e-07 ***
batch8       0.495901   0.108926    4.55  5.3e-06 ***
batch9       0.385793   0.118593    3.25   0.0011 ** 
temp         0.010967   0.000413   26.58  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 84.8 on 12 Df
Pseudo R-squared: 0.962
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> 
> 
> 
> cleanEx()
> nameEx("betatree")
> ### * betatree
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betatree
> ### Title: Beta Regression Trees
> ### Aliases: betatree plot.betatree print.betatree predict.betatree
> ###   sctest.betatree
> ### Keywords: tree
> 
> ### ** Examples
> 
> options(digits = 4)
> suppressWarnings(RNGversion("3.5.0"))
> 
> ## data with two groups of dyslexic and non-dyslexic children
> data("ReadingSkills", package = "betareg")
> ## additional random noise (not associated with reading scores)
> set.seed(1071)
> ReadingSkills$x1 <- rnorm(nrow(ReadingSkills))
> ReadingSkills$x2 <- runif(nrow(ReadingSkills))
> ReadingSkills$x3 <- factor(rnorm(nrow(ReadingSkills)) > 0)
> 
> ## fit beta regression tree: in each node
> ##   - accurcay's mean and precision depends on iq
> ##   - partitioning is done by dyslexia and the noise variables x1, x2, x3
> ## only dyslexia is correctly selected for splitting
> bt <- betatree(accuracy ~ iq | iq, ~ dyslexia + x1 + x2 + x3,
+   data = ReadingSkills, minsize = 10)
> plot(bt)
> 
> ## inspect result
> coef(bt)
  (Intercept)       iq (phi)_(Intercept) (phi)_iq
2      1.6565  1.46571             1.273    2.048
3      0.3809 -0.08623             4.808    0.826
> if(require("strucchange")) sctest(bt)
Loading required package: strucchange
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

Loading required package: sandwich
$`1`
           dyslexia     x1     x2     x3
statistic 2.269e+01 8.5251 5.5699 1.0568
p.value   5.848e-04 0.9095 0.9987 0.9999

$`2`
          dyslexia     x1     x2     x3
statistic        0 6.4116 4.5170 4.2308
p.value         NA 0.8412 0.9752 0.7566

$`3`
NULL

> ## IGNORE_RDIFF_BEGIN
> summary(bt, node = 2)

Call:
betatree(formula = accuracy ~ iq | iq, data = ReadingSkills)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.495 -0.437  0.210  0.953  1.090 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.657      0.286    5.78  7.3e-09 ***
iq             1.466      0.248    5.92  3.2e-09 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.273      0.307    4.15  3.4e-05 ***
iq             2.048      0.331    6.19  5.9e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 39.4 on 4 Df
Pseudo R-squared: 0.149
Number of iterations: 17 (BFGS) + 2 (Fisher scoring) 
> summary(bt, node = 3)

Call:
betatree(formula = accuracy ~ iq | iq, data = ReadingSkills)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.426 -0.631 -0.067  0.778  1.555 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   0.3809     0.0486    7.83  4.8e-15 ***
iq           -0.0862     0.0549   -1.57     0.12    

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    4.808      0.414   11.61   <2e-16 ***
iq             0.826      0.395    2.09    0.036 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 27.3 on 4 Df
Pseudo R-squared: 0.0391
Number of iterations: 16 (BFGS) + 2 (Fisher scoring) 
> ## IGNORE_RDIFF_END
> 
> ## add a numerical variable with relevant information for splitting
> ReadingSkills$x4 <- rnorm(nrow(ReadingSkills), c(-1.5, 1.5)[ReadingSkills$dyslexia])
> 
> bt2 <- betatree(accuracy ~ iq | iq, ~ x1 + x2 + x3 + x4,
+   data = ReadingSkills, minsize = 10)
> plot(bt2)
> 
> ## inspect result
> coef(bt2)
  (Intercept)      iq (phi)_(Intercept) (phi)_iq
2      1.7060 1.47402             1.293   2.0841
3      0.5048 0.03391             3.131  -0.7684
> if(require("strucchange")) sctest(bt2)
$`1`
              x1     x2     x3       x4
statistic 8.5251 5.5699 1.0568 19.94405
p.value   0.9095 0.9987 0.9999  0.03485

$`2`
              x1     x2     x3     x4
statistic 8.9467 3.5888 3.5677 4.7049
p.value   0.5964 0.9985 0.9197 0.9848

$`3`
              x1     x2     x3     x4
statistic 5.5413 1.2373 4.8649 4.9921
p.value   0.6595 0.9997 0.7619 0.7432

> ## IGNORE_RDIFF_BEGIN
> summary(bt2, node = 2)

Call:
betatree(formula = accuracy ~ iq | iq, data = ReadingSkills)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.583 -0.393  0.177  0.923  1.054 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.706      0.292    5.85  4.9e-09 ***
iq             1.474      0.248    5.95  2.7e-09 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.293      0.312    4.14  3.4e-05 ***
iq             2.084      0.333    6.25  4.0e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 38.6 on 4 Df
Pseudo R-squared: 0.163
Number of iterations: 17 (BFGS) + 1 (Fisher scoring) 
> summary(bt2, node = 3)

Call:
betatree(formula = accuracy ~ iq | iq, data = ReadingSkills)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.070 -0.584 -0.156  0.639  2.188 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   0.5048     0.1245    4.05    5e-05 ***
iq            0.0339     0.0998    0.34     0.73    

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    3.131      0.370    8.45   <2e-16 ***
iq            -0.768      0.359   -2.14    0.032 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 22.4 on 4 Df
Pseudo R-squared: 0.0378
Number of iterations: 16 (BFGS) + 1 (Fisher scoring) 
> ## IGNORE_RDIFF_END
> 
> 
> 
> cleanEx()

detaching ‘package:strucchange’, ‘package:sandwich’, ‘package:zoo’

> nameEx("gleverage")
> ### * gleverage
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gleverage
> ### Title: Generalized Leverage Values
> ### Aliases: gleverage gleverage.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> options(digits = 4)
> data("GasolineYield", package = "betareg")
> gy <- betareg(yield ~ batch + temp, data = GasolineYield)
> gleverage(gy)
     1      2      3      4      5      6      7      8      9     10     11 
0.2167 0.2517 0.3254 0.4542 0.2239 0.3201 0.5271 0.2819 0.3011 0.5066 0.1970 
    12     13     14     15     16     17     18     19     20     21     22 
0.2146 0.3054 0.4397 0.2909 0.3514 0.4049 0.2448 0.3570 0.4840 0.2154 0.1835 
    23     24     25     26     27     28     29     30     31     32 
0.2899 0.4701 0.2910 0.2982 0.5449 0.3677 0.6603 0.3181 0.2557 0.4569 
> 
> 
> 
> cleanEx()
> nameEx("plot.betareg")
> ### * plot.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.betareg
> ### Title: Diagnostic Plots for betareg Objects
> ### Aliases: plot.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> 
> gy <- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)
> 
> par(mfrow = c(3, 2))
> plot(gy, which = 1:6)
> par(mfrow = c(1, 1))
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("predict.betareg")
> ### * predict.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.betareg
> ### Title: Prediction Method for betareg Objects
> ### Aliases: predict.betareg pit.betareg rootogram.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> options(digits = 4)
> 
> data("GasolineYield", package = "betareg")
> 
> gy2 <- betareg(yield ~ batch + temp | temp, data = GasolineYield)
> 
> cbind(
+   predict(gy2, type = "response"),
+   predict(gy2, type = "link"),
+   predict(gy2, type = "precision"),
+   predict(gy2, type = "variance"),
+   predict(gy2, type = "quantile", at = c(0.25, 0.5, 0.75))
+ )
                                      q_0.25   q_0.5  q_0.75
1  0.09997 -2.1976   77.56 1.145e-03 0.07549 0.09653 0.12074
2  0.18658 -1.4724  215.06 7.024e-04 0.16816 0.18561 0.20394
3  0.32143 -0.7472  596.36 3.651e-04 0.30842 0.32123 0.33422
4  0.47379 -0.1049 1471.75 1.693e-04 0.46500 0.47378 0.48256
5  0.08568 -2.3676   93.73 8.269e-04 0.06490 0.08273 0.10328
6  0.14212 -1.7978  208.89 5.809e-04 0.12525 0.14097 0.15774
7  0.26285 -1.0312  614.00 3.151e-04 0.25073 0.26259 0.27469
8  0.10324 -2.1617   85.88 1.066e-03 0.07972 0.10017 0.12344
9  0.17652 -1.5401  205.86 7.027e-04 0.15806 0.17547 0.19384
10 0.30245 -0.8357  554.46 3.798e-04 0.28916 0.30221 0.31547
11 0.07881 -2.4587  120.07 5.996e-04 0.06119 0.07647 0.09390
12 0.14365 -1.7853  309.57 3.961e-04 0.12981 0.14288 0.15665
13 0.24751 -1.1120  798.12 2.331e-04 0.23709 0.24730 0.25769
14 0.34394 -0.6458 1537.51 1.467e-04 0.33573 0.34387 0.35208
15 0.16957 -1.5887  342.81 4.096e-04 0.15556 0.16892 0.18287
16 0.27545 -0.9671  821.72 2.426e-04 0.26484 0.27527 0.28586
17 0.33691 -0.6771 1235.66 1.806e-04 0.32780 0.33683 0.34594
18 0.10548 -2.1378  191.40 4.904e-04 0.08984 0.10410 0.11962
19 0.23606 -1.1744  742.04 2.427e-04 0.22542 0.23583 0.24645
20 0.32316 -0.7393 1368.34 1.597e-04 0.31459 0.32308 0.33164
21 0.05383 -2.8665  120.07 4.207e-04 0.03893 0.05137 0.06608
22 0.07928 -2.4521  215.06 3.379e-04 0.06624 0.07798 0.09091
23 0.16906 -1.5923  720.73 1.946e-04 0.15949 0.16876 0.17831
24 0.27063 -0.9914 1677.97 1.176e-04 0.26326 0.27054 0.27789
25 0.08270 -2.4062  248.80 3.037e-04 0.07039 0.08158 0.09380
26 0.17116 -1.5774  798.12 1.775e-04 0.16202 0.17088 0.18000
27 0.31885 -0.7590 2523.27 8.604e-05 0.31257 0.31881 0.32509
28 0.12701 -1.9276  650.84 1.701e-04 0.11801 0.12663 0.13560
29 0.23661 -1.1714 1885.42 9.575e-05 0.22995 0.23651 0.24316
30 0.10508 -2.1420  798.12 1.177e-04 0.09759 0.10475 0.11221
31 0.11952 -1.9970  978.71 1.074e-04 0.11239 0.11926 0.12637
32 0.18402 -1.4894 1998.57 7.509e-05 0.17811 0.18391 0.18980
> 
> ## evaluate cumulative _p_robabilities for (small) new data set
> gyd <- GasolineYield[c(1, 5, 10), ]
> 
> ## CDF at 0.1 for each observation
> predict(gy2, newdata = gyd, type = "probability", at = 0.1)
Warning: contrasts dropped from factor batch
        1         5        10 
5.407e-01 7.165e-01 6.053e-40 
> 
> ## CDF at each combination of 0.1/0.2 and observations
> predict(gy2, newdata = gyd, type = "probability", at = c(0.1, 0.2))
Warning: contrasts dropped from factor batch
       p_0.1     p_0.2
1  5.407e-01 9.933e-01
5  7.165e-01 9.991e-01
10 6.053e-40 5.828e-09
> 
> ## CDF at elementwise combinations of 0.1/0.2/0.3 and observations
> predict(gy2, newdata = gyd, type = "probability", at = c(0.1, 0.2, 0.3))
Warning: contrasts dropped from factor batch
     1      5     10 
0.5407 0.9991 0.4549 
> predict(gy2, newdata = gyd, type = "probability", at = c(0.1, 0.2, 0.3), elementwise = TRUE)
Warning: contrasts dropped from factor batch
     1      5     10 
0.5407 0.9991 0.4549 
> 
> ## CDF at all combinations of 0.1/0.2/0.3 and observations
> predict(gy2, newdata = gyd, type = "probability", at = c(0.1, 0.2, 0.3), elementwise = FALSE)
Warning: contrasts dropped from factor batch
       p_0.1     p_0.2  p_0.3
1  5.407e-01 9.933e-01 1.0000
5  7.165e-01 9.991e-01 1.0000
10 6.053e-40 5.828e-09 0.4549
> 
> 
> 
> cleanEx()
> nameEx("residuals.betareg")
> ### * residuals.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: residuals.betareg
> ### Title: Residuals Method for betareg Objects
> ### Aliases: residuals.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> options(digits = 4)
> 
> data("GasolineYield", package = "betareg")
> 
> gy <- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)
> 
> gy_res <- cbind(
+   "quantile"   = residuals(gy, type = "quantile"),
+   "pearson"    = residuals(gy, type = "pearson"),
+   "deviance"   = residuals(gy, type = "deviance"),
+   "response"   = residuals(gy, type = "response"),
+   "weighted"   = residuals(gy, type = "weighted"),
+   "sweighted"  = residuals(gy, type = "sweighted"),
+   "sweighted2" = residuals(gy, type = "sweighted2")
+ )
> pairs(gy_res)
> 
> cor(gy_res)
           quantile pearson deviance response weighted sweighted sweighted2
quantile     1.0000  0.9980   0.9997   0.9659   0.9995    0.9995     0.9980
pearson      0.9980  1.0000   0.9984   0.9739   0.9956    0.9956     0.9941
deviance     0.9997  0.9984   1.0000   0.9682   0.9989    0.9989     0.9976
response     0.9659  0.9739   0.9682   1.0000   0.9609    0.9609     0.9652
weighted     0.9995  0.9956   0.9989   0.9609   1.0000    1.0000     0.9985
sweighted    0.9995  0.9956   0.9989   0.9609   1.0000    1.0000     0.9985
sweighted2   0.9980  0.9941   0.9976   0.9652   0.9985    0.9985     1.0000
> 
> 
> 
> cleanEx()
> nameEx("summary.betareg")
> ### * summary.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.betareg
> ### Title: Methods for betareg Objects
> ### Aliases: print.betareg summary.betareg print.summary.betareg
> ###   coef.betareg vcov.betareg bread.betareg estfun.betareg
> ###   coeftest.betareg logLik.betareg terms.betareg model.frame.betareg
> ###   model.matrix.betareg cooks.distance.betareg hatvalues.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> options(digits = 4)
> 
> data("GasolineYield", package = "betareg")
> 
> gy2 <- betareg(yield ~ batch + temp | temp, data = GasolineYield)
> 
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp | temp, data = GasolineYield)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.104 -0.585 -0.143  0.690  2.520 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -5.923236   0.183526  -32.27  < 2e-16 ***
batch1       1.601988   0.063856   25.09  < 2e-16 ***
batch2       1.297266   0.099100   13.09  < 2e-16 ***
batch3       1.565338   0.099739   15.69  < 2e-16 ***
batch4       1.030072   0.063288   16.28  < 2e-16 ***
batch5       1.154163   0.065643   17.58  < 2e-16 ***
batch6       1.019445   0.066351   15.36  < 2e-16 ***
batch7       0.622259   0.065632    9.48  < 2e-16 ***
batch8       0.564583   0.060185    9.38  < 2e-16 ***
batch9       0.359439   0.067141    5.35  8.6e-08 ***
temp         0.010359   0.000436   23.75  < 2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  1.36409    1.22578    1.11     0.27    
temp         0.01457    0.00362    4.03  5.7e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:   87 on 13 Df
Pseudo R-squared: 0.952
Number of iterations: 33 (BFGS) + 28 (Fisher scoring) 
> coef(gy2)
      (Intercept)            batch1            batch2            batch3 
         -5.92324           1.60199           1.29727           1.56534 
           batch4            batch5            batch6            batch7 
          1.03007           1.15416           1.01944           0.62226 
           batch8            batch9              temp (phi)_(Intercept) 
          0.56458           0.35944           0.01036           1.36409 
       (phi)_temp 
          0.01457 
> vcov(gy2)
                  (Intercept)     batch1     batch2     batch3     batch4
(Intercept)         3.368e-02 -4.124e-03 -8.216e-03 -8.839e-03 -3.672e-03
batch1             -4.124e-03  4.078e-03  2.483e-03  2.524e-03  2.189e-03
batch2             -8.216e-03  2.483e-03  9.821e-03  3.401e-03  2.395e-03
batch3             -8.839e-03  2.524e-03  3.401e-03  9.948e-03  2.427e-03
batch4             -3.672e-03  2.189e-03  2.395e-03  2.427e-03  4.005e-03
batch5             -4.461e-03  2.240e-03  2.548e-03  2.594e-03  2.206e-03
batch6             -3.902e-03  2.204e-03  2.439e-03  2.475e-03  2.178e-03
batch7             -3.007e-03  2.146e-03  2.267e-03  2.285e-03  2.133e-03
batch8             -6.259e-04  1.993e-03  1.804e-03  1.775e-03  2.013e-03
batch9             -1.801e-03  2.068e-03  2.031e-03  2.026e-03  2.072e-03
temp               -7.753e-05  4.999e-06  1.504e-05  1.657e-05  3.891e-06
(phi)_(Intercept)  -1.860e-02  1.682e-04  9.769e-04  1.420e-03  1.409e-04
(phi)_temp          4.618e-05  2.069e-07 -1.937e-06 -2.948e-06  6.530e-08
                      batch5     batch6     batch7     batch8     batch9
(Intercept)       -4.461e-03 -3.902e-03 -3.007e-03 -6.259e-04 -1.801e-03
batch1             2.240e-03  2.204e-03  2.146e-03  1.993e-03  2.068e-03
batch2             2.548e-03  2.439e-03  2.267e-03  1.804e-03  2.031e-03
batch3             2.594e-03  2.475e-03  2.285e-03  1.775e-03  2.026e-03
batch4             2.206e-03  2.178e-03  2.133e-03  2.013e-03  2.072e-03
batch5             4.309e-03  2.223e-03  2.156e-03  1.977e-03  2.065e-03
batch6             2.223e-03  4.402e-03  2.140e-03  2.003e-03  2.070e-03
batch7             2.156e-03  2.140e-03  4.308e-03  2.044e-03  2.078e-03
batch8             1.977e-03  2.003e-03  2.044e-03  3.622e-03  2.100e-03
batch9             2.065e-03  2.070e-03  2.078e-03  2.100e-03  4.508e-03
temp               5.827e-06  4.454e-06  2.259e-06 -3.585e-06 -7.000e-07
(phi)_(Intercept)  1.011e-03  5.045e-04 -4.523e-04 -1.307e-03 -3.533e-04
(phi)_temp        -2.185e-06 -8.969e-07  1.470e-06  3.675e-06  1.119e-06
                        temp (phi)_(Intercept) (phi)_temp
(Intercept)       -7.753e-05        -1.860e-02  4.618e-05
batch1             4.999e-06         1.682e-04  2.069e-07
batch2             1.504e-05         9.769e-04 -1.937e-06
batch3             1.657e-05         1.420e-03 -2.948e-06
batch4             3.891e-06         1.409e-04  6.530e-08
batch5             5.827e-06         1.011e-03 -2.185e-06
batch6             4.454e-06         5.045e-04 -8.969e-07
batch7             2.259e-06        -4.523e-04  1.470e-06
batch8            -3.585e-06        -1.307e-03  3.675e-06
batch9            -7.000e-07        -3.533e-04  1.119e-06
temp               1.902e-07         4.666e-05 -1.175e-07
(phi)_(Intercept)  4.666e-05         1.503e+00 -4.342e-03
(phi)_temp        -1.175e-07        -4.342e-03  1.309e-05
> logLik(gy2)
'log Lik.' 86.98 (df=13)
> AIC(gy2)
[1] -148
> 
> coef(gy2, model = "mean")
(Intercept)      batch1      batch2      batch3      batch4      batch5 
   -5.92324     1.60199     1.29727     1.56534     1.03007     1.15416 
     batch6      batch7      batch8      batch9        temp 
    1.01944     0.62226     0.56458     0.35944     0.01036 
> coef(gy2, model = "precision")
(Intercept)        temp 
    1.36409     0.01457 
> summary(gy2, phi = FALSE)

Call:
betareg(formula = yield ~ batch + temp | temp, data = GasolineYield)

Quantile residuals:
   Min     1Q Median     3Q    Max 
-2.104 -0.585 -0.143  0.690  2.520 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -5.923236   0.183526  -32.27  < 2e-16 ***
batch1       1.601988   0.063856   25.09  < 2e-16 ***
batch2       1.297266   0.099100   13.09  < 2e-16 ***
batch3       1.565338   0.099739   15.69  < 2e-16 ***
batch4       1.030072   0.063288   16.28  < 2e-16 ***
batch5       1.154163   0.065643   17.58  < 2e-16 ***
batch6       1.019445   0.066351   15.36  < 2e-16 ***
batch7       0.622259   0.065632    9.48  < 2e-16 ***
batch8       0.564583   0.060185    9.38  < 2e-16 ***
batch9       0.359439   0.067141    5.35  8.6e-08 ***
temp         0.010359   0.000436   23.75  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:   87 on 13 Df
Pseudo R-squared: 0.952
Number of iterations: 33 (BFGS) + 28 (Fisher scoring) 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  15.072 0.179 15.304 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
